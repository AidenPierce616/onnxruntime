// This file is generated by compile_sparse_attention.py
/* clang-format off */
#include "contrib_ops/cuda/sparse/sparse_attention_trition/sparse_attention_common.h"

namespace onnxruntime {{
namespace contrib {{
namespace cuda {{

// globals
#define CUBIN_NAME {kernel_name}_cubin
CUmodule {kernel_name}_mod = NULL;
CUfunction {kernel_name}_func = NULL;
unsigned char CUBIN_NAME[{bin_size}] = {{ {bin_data} }};

void unload_{kernel_name}(void) {{
    CU_CALL_THROW(cuModuleUnload({kernel_name}_mod));
}}

void load_{kernel_name}(void) {{
    void *bin = (void *)&CUBIN_NAME;
    CU_CALL_THROW(cuModuleLoadData(&{kernel_name}_mod, bin));
    CU_CALL_THROW(cuModuleGetFunction(&{kernel_name}_func, {kernel_name}_mod, "{triton_kernel_name}"));
    constexpr int shared = {shared};
    if constexpr (shared > 49152) {{
      SetKernelSharedMemory({kernel_name}_func);
    }}
}}

/*
{kernel_docstring}
*/
Status {kernel_name}(SparseAttentionParams& params) {{
    return params.LaunchKernel({kernel_name}_func, {block_m}, {num_warps} * 32, {shared});
}}

}}  // namespace cuda
}}  // namespace contrib
}}  // namespace onnxruntime
